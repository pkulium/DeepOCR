# Data Preparation Guide

This guide explains how to prepare the training datasets for Easy Deep-OCR. The model requires two datasets across two training stages.

## ğŸ“‹ Overview

| Stage | Dataset | Size | Purpose | Format |
|-------|---------|------|---------|--------|
| Stage 1: Alignment | LLaVA-CC3M-Pretrain-595K | 595K | Initialize projector | Direct download |
| Stage 2: Pretraining | olmOCR-mix-1025 | 260k | Train full model | Requires conversion |

## ğŸ”§ Prerequisites

```bash
# Install Hugging Face CLI
pip install huggingface-hub

# Login to Hugging Face (if needed)
huggingface-cli login
```

## ğŸ“¦ Stage 1: LLaVA-CC3M-Pretrain-595K

### Download

This dataset can be used directly without conversion:

```bash
# Download the dataset
huggingface-cli download liuhaotian/LLaVA-CC3M-Pretrain-595K \
    --repo-type dataset \
    --local-dir ./data/LLaVA-CC3M-Pretrain-595K
```

### Dataset Structure

```
data/LLaVA-CC3M-Pretrain-595K/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ 000000000001.jpg
â”‚   â”œâ”€â”€ 000000000002.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ chat.json
```

The dataset is ready to use for Stage 1 alignment training.

## ğŸ“¦ Stage 2: olmOCR-mix-1025

This dataset requires format conversion to be compatible with the VILA training pipeline.

### Step 1: Download Raw Data

```bash
# Download the dataset
huggingface-cli download allenai/olmOCR-mix-1025 \
    --repo-type dataset \
    --local-dir ./data/olmOCR-mix-1025-raw
```

### Step 2: Convert to Intermediate JSON Format

The first conversion script transforms the dataset into a standardized JSON format:

```bash
cd data_prepare

python convert_to_json.py

```

Note: You must update the file paths inside the Python script before running it.

**What this does:**
- Parses the original olmOCR format
- Extracts image paths and annotations
- Creates a unified JSON structure
- Validates data integrity

**Output structure:**
```
data/olmOCR-mix-1025-json/
â”œâ”€â”€ annotations.json
â””â”€â”€ images/
    â”œâ”€â”€ doc_0001.pdf (or .png/.jpg)
    â”œâ”€â”€ doc_0002.pdf
    â””â”€â”€ ...
```

### Step 3: Convert to LLaVA Training Format

The second conversion script transforms the data into the format required for VILA training, with images converted to PNG:

```bash
python convert_to_llava.py 

```

**What this does:**
- Converts all images to PNG format
- Creates conversation-style annotations
- Formats data for multi-turn dialogue training
- Generates the final `chat.json` file

**Output structure:**
```
data/olmOCR-mix-1025-llava/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ doc_0001.png
â”‚   â”œâ”€â”€ doc_0002.png
â”‚   â””â”€â”€ ...
â””â”€â”€ chat.json
```

### Final Dataset Format

The `chat.json` file follows this structure:

```json
[
    {
        "id": "doc_0001",
        "image": "images/doc_0001.png",
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nFree OCR."
            },
            {
                "from": "gpt",
                "value": "Extracted text content..."
            }
        ]
    },
    ...
]
```

## ğŸš€ Complete Pipeline

Run all steps in sequence:

```bash
# Step 1: Download LLaVA-CC3M
huggingface-cli download liuhaotian/LLaVA-CC3M-Pretrain-595K \
    --repo-type dataset \
    --local-dir ./data/LLaVA-CC3M-Pretrain-595K

# Step 2: Download olmOCR-mix
huggingface-cli download allenai/olmOCR-mix-1025 \
    --repo-type dataset \
    --local-dir ./data/olmOCR-mix-1025-raw

# Step 3: Convert olmOCR to JSON
cd data_prepare
python convert_to_json.py 

# Step 4: Convert to LLaVA format with PNG images
python convert_to_llava.py 
```

## ğŸ“ Final Directory Structure

After completing all steps, your data directory should look like this:

```
data/
â”œâ”€â”€ LLaVA-CC3M-Pretrain-595K/          # Stage 1 data (ready to use)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ chat.json
â”‚
â”œâ”€â”€ olmOCR-mix-1025-raw/               # Downloaded raw data
â”‚   â””â”€â”€ [original files]
â”‚
â”œâ”€â”€ olmOCR-mix-1025-json/              # Intermediate format
â”‚   â”œâ”€â”€ annotations.json
â”‚   â””â”€â”€ images/
â”‚
â””â”€â”€ olmOCR-mix-1025-llava/             # Stage 2 data (ready to use)
    â”œâ”€â”€ images/                         # All images in PNG format
    â””â”€â”€ chat.json
```

## ğŸ” Data Preparation Scripts

All conversion scripts are located in the `data_prepare/` folder:

```
data_prepare/
â”œâ”€â”€ convert_to_json.py      # Step 1: Raw data â†’ JSON format
â”œâ”€â”€ convert_to_llava.py     # Step 2: JSON â†’ LLaVA format + PNG conversion
â””â”€â”€ README.md               # This file
```


```


## ğŸ› Troubleshooting

### Issue: Download fails or is interrupted

```bash
# Resume download by re-running the command
huggingface-cli download <dataset> --resume-download
```

## ğŸ“š Next Steps

After data preparation is complete, proceed to training:

1. **Stage 1 - Alignment**: Use `LLaVA-CC3M-Pretrain-595K`
   ```bash
   bash scripts/NVILA-Lite/align_ocr.sh
   ```

2. **Stage 2 - Pretraining**: Use `olmOCR-mix-1025-llava`
   ```bash
   bash scripts/NVILA-Lite/pretrain_ocr.sh
   ```

See the main [README.md](../README.md) for detailed t